{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78c5682",
   "metadata": {},
   "source": [
    "### 分段读取数据并进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b855a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "for i in range(10):    \n",
    "    print(i, end= '\\r')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa6a49ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\r"
     ]
    }
   ],
   "source": [
    "# 按行读取数据\n",
    "line_num = 0 # 记录读取的行数\n",
    "cops_num = 0 # 记录包含cops的行数\n",
    "# windows users may need to add encoding = 'utf8' into the folling line.\n",
    "with open('eg.txt', 'r',encoding='utf-8') as f:\n",
    "    for i in f:\n",
    "        line_num += 1\n",
    "        if '南京大学' in i:\n",
    "            cops_num += 1\n",
    "        if line_num % 10 ==0:\n",
    "            print(line_num, end='\\r')\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bc09cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de2af31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3181818181818182"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cops_num / line_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9697a024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "# 读取文件的前chunkSize行，并将其写入另一个文件\n",
    "bigfile = open('eg.txt', 'r', encoding='utf-8')\n",
    "chunkSize = 1000000\n",
    "chunk = bigfile.readlines(chunkSize)\n",
    "print(len(chunk))\n",
    "# with open(\"../data/ows_tweets_sample.txt\", 'w') as f:\n",
    "#     for i in chunk:\n",
    "#         f.write(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d725ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 44\r"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/519633/lazy-method-for-reading-big-file-in-python?lq=1\n",
    "import csv\n",
    "import time\n",
    "bigfile = open('eg.txt', 'r',encoding='utf-8')\n",
    "chunkSize = 10**8 # 每次读取的数据量\n",
    "chunk = bigfile.readlines(chunkSize) # 第一次读取的数据块\n",
    "num_chunk, num_lines, num_cops = 0, 0, 0\n",
    "# 分别代表当前读取的数据块编号，已经读取的总行数，读取到的包含cops的总行数\n",
    "\n",
    "while chunk:\n",
    "    lines = csv.reader((line.replace('\\x00','') for line in chunk), \n",
    "                       delimiter=',', quotechar='\"')\n",
    "    # do sth.\n",
    "    num_lines += len(list(lines))# 更新已经读取的总行数\n",
    "#     for i in lines:\n",
    "#         if 'cops' in i:\n",
    "#             num_cops +=1\n",
    "    if num_chunk % 5 ==0:\n",
    "        print(num_chunk, num_lines, end = '\\r')\n",
    "    num_chunk += 1\n",
    "    chunk = bigfile.readlines(chunkSize) # read another chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf2e555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c1143c",
   "metadata": {},
   "source": [
    "### 用pandas的get_chunk功能处理亿级别的数据\n",
    "（超过5TB）\n",
    "\n",
    "(下文所处理的文件没找到源文件所以会有filenotfound的bug 全部忽略）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "879bb369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "f = open('/Users/datalab/bigdata/cjc/ows-raw.txt',encoding='utf-8')\n",
    "reader = pd.read_table(f,  sep=',',  quotechar='\"', iterator=True, on_bad_lines='skip') \n",
    "# 使用read_table读取表格对象 定义分隔符sep，括起字段的字符quotechar，是否返回迭代器，如何处理错误航\n",
    "\n",
    "chunkSize = 100000\n",
    "chunk = reader.get_chunk(chunkSize)\n",
    "len(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7002d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_head() # 返回前若干行（无参数默认前五行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f46b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "f = open('/Users/datalab/bigdata/cjc/ows-raw.txt',encoding='utf-8')\n",
    "reader = pd.read_table(f,  sep=',',  quotechar='\"', \n",
    "                       iterator=True, on_bad_lines='skip') #跳过报错行\n",
    "chunkSize = 100000\n",
    "loop = True\n",
    "cops_data = []\n",
    "num_chunk, num_lines = 0, 0\n",
    "while loop:\n",
    "    try:\n",
    "        chunk = reader.get_chunk(chunkSize)\n",
    "        # dat = data_cleaning_funtion(chunk) \n",
    "        # do sth. e.g., if cops in dat\n",
    "        # 筛选出包含cops的行\n",
    "        dat=[chunk.loc[k] for k in chunk.index if 'cops' in str(chunk['Text'][k])]\n",
    "        \n",
    "        # k表示数据块中每一行的索引，chunk_index表示数据块的索引（刻碟带对象，包含数据库中每一行的索引值）\n",
    "        # chunk['Text'][k]表示数据块中第k行的‘Text’值\n",
    "        # chunk.loc[k]是访问pandas.DataFrame 对象的方法\n",
    "        \n",
    "        num_lines += len(chunk) # 更新已经读取的总行数\n",
    "        print(num_chunk, num_lines, end = '\\r')\n",
    "        num_chunk +=1 # 更新块编号\n",
    "        for d in dat:\n",
    "            cops_data.append(d) # 更新列表（将筛选出来的行添加到列表中）\n",
    "    except StopIteration:\n",
    "        loop = False\n",
    "        print(\"Iteration is stopped.\")\n",
    "#df = pd.concat(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cops_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56308abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dat,ignore_index=True)\n",
    "# pd.concat() 是 pandas 库中的一个函数，它用来将多个 pandas 对象（如 Series、DataFrame 等）沿着指定轴连接起来。\n",
    "# 如：对于两个数据库df1和df2\n",
    "# df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "# df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "# 可以：\n",
    "# result = pd.concat([df1, df2], ignore_index=True)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58308e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(cops_data) # 从字典/字典列表创建数据框\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
